{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler , Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Meriem/Desktop/predictor/covid.csv\")\n",
    "\n",
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Peeking into Data\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Shape of dataset\")\n",
    "print(\"Rows:\",df.shape[0],\"\\nColumns:\",df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Description\",df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_columns = df.filter(like='Severity_').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Severity_None'].replace({1:'None',0:'No'},inplace =True)\n",
    "df['Severity_Mild'].replace({1:'Mild',0:'No'},inplace =True)\n",
    "df['Severity_Moderate'].replace({1:'Moderate',0:'No'},inplace =True)\n",
    "df['Severity_Severe'].replace({1:'Severe',0:'No'},inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition']=df[severity_columns].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing(list1):\n",
    "    list1 = set(list1) \n",
    "    list1.discard(\"No\")\n",
    "    a = ''.join(list1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Condition'] = df['Condition'].apply(removing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_columns = df.filter(like='Age_').columns\n",
    "gender_columns = df.filter(like='Gender_').columns\n",
    "contact_columns = df.filter(like='Contact_').columns\n",
    "No_risk_age = df.groupby(['Severity_None'])[age_columns].sum()\n",
    "No_risk_gender = df.groupby(['Severity_None'])[gender_columns].sum()\n",
    "No_risk_contact = df.groupby(['Severity_None'])[contact_columns].sum()\n",
    "Low_risk_age = df.groupby(['Severity_Mild'])[age_columns].sum()\n",
    "Low_risk_gender = df.groupby(['Severity_Mild'])[gender_columns].sum()\n",
    "Low_risk_contact = df.groupby(['Severity_Mild'])[contact_columns].sum()\n",
    "Moderate_risk_age = df.groupby(['Severity_Moderate'])[age_columns].sum()\n",
    "Moderate_risk_gender = df.groupby(['Severity_Moderate'])[gender_columns].sum()\n",
    "Moderate_risk_contact = df.groupby(['Severity_Moderate'])[contact_columns].sum()\n",
    "Severe_risk_age = df.groupby(['Severity_Severe'])[age_columns].sum()\n",
    "Severe_risk_gender = df.groupby(['Severity_Severe'])[gender_columns].sum()\n",
    "Severe_risk_contact = df.groupby(['Severity_Severe'])[contact_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(severity_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Symptoms_Score'] = df.iloc[:,:5].sum(axis=1) + df.iloc[:,6:10].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['Condition'] = le.fit_transform(df['Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(['Condition'],axis=1)\n",
    "y= df['Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import model_from_json\n",
    "model = LogisticRegression(solver = 'lbfgs')\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model.json\", \"w\") as json_file:\n",
    " #   json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"model.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "#json_file = open('model_num.json', 'r')\n",
    "\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "#loaded_model.load_weights(\"model_num.h5\")\n",
    "#print(\"Loaded model from disk\")\n",
    "\n",
    "#loaded_model.save('model_num.hdf5')\n",
    "#loaded_model=load_model('model_num.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkl_Filename = \"Pickle_RL_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Pkl_Filename, 'rb') as file:  \n",
    "    Pickled_model = pickle.load(file)\n",
    "\n",
    "Pickled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = Pickled_model.score(X_train, y_train)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "Ypredict = Pickled_model.predict(X_test)  \n",
    "\n",
    "Ypredict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# load json and create model\n",
    "#json_file = open('model.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#loaded_model.load_weights(\"model.h5\")\n",
    "#print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RL_Model to file in the current working directory\n",
    "\n",
    "joblib_file = \"joblib_model.pkl\"  \n",
    "joblib.dump(model, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_model = joblib.load(joblib_file)\n",
    "\n",
    "\n",
    "joblib_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy score and predict target values\n",
    "\n",
    "# Calculate the Score \n",
    "score = joblib_model.score(X_test, y_test)  \n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# Predict the Labels using the reloaded Model\n",
    "Ypredict = joblib_model.predict(X_test)  \n",
    "\n",
    "Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg(LogisticRegression):\n",
    "\n",
    "    # Override the class constructor\n",
    "    def __init__(self, C=1.0, solver='lbfgs', max_iter=100, X_train=None, y_train=None):\n",
    "        LogisticRegression.__init__(self, C=C, solver=solver, max_iter=max_iter)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # A method for saving object data to JSON file\n",
    "    def save_json(self, filepath):\n",
    "        dict_ = {}\n",
    "        dict_['C'] = self.C\n",
    "        dict_['max_iter'] = self.max_iter\n",
    "        dict_['solver'] = self.solver\n",
    "        dict_['X_train'] = self.X_train.tolist() if self.X_train is not None else 'None'\n",
    "        dict_['y_train'] = self.y_train.tolist() if self.y_train is not None else 'None'\n",
    "\n",
    "        # Creat json and save to file\n",
    "        json_txt = json.dumps(dict_, indent=4)\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.write(json_txt)\n",
    "\n",
    "    # A method for loading data from JSON file\n",
    "    def load_json(self, filepath):\n",
    "        with open(filepath, 'r') as file:\n",
    "            dict_ = json.load(file)\n",
    "\n",
    "        self.C = dict_['C']\n",
    "        self.max_iter = dict_['max_iter']\n",
    "        self.solver = dict_['solver']\n",
    "        self.X_train = np.asarray(dict_['X_train']) if dict_['X_train'] != 'None' else None\n",
    "        self.y_train = np.asarray(dict_['y_train']) if dict_['y_train'] != 'None' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"mylogreg.json\"\n",
    "\n",
    "# Create a model and train it\n",
    "mylogreg = MyLogReg(X_train=y_train, y_train=y_train)  \n",
    "mylogreg.save_json(filepath)\n",
    "\n",
    "# Create a new object and load its data from JSON file\n",
    "json_mylogreg = MyLogReg()  \n",
    "json_mylogreg.load_json(filepath)  \n",
    "json_mylogreg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to make predictions with the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "round(accuracy_score(y_test,y_pred)*350,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = [[1,1,1,1,1,0,1,1,1,1,0,1,0,0,0,0,0,1,0,1,0,0,0]]\n",
    "# make a prediction\n",
    "ynew = model.predict(Xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
